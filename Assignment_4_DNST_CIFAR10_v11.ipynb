{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-4-DNST_CIFAR10_v11.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/raghumriyer/working/blob/master/Assignment_4_DNST_CIFAR10_v11.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_filter = 12\n",
        "dropout_rate = 0.2\n",
        "l = 12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "outputId": "17090c4a-5b99-4187-cd3d-0fb574e0cc0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9744
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 32, 32, 12)   324         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 12)   48          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 32, 32, 12)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 32, 32, 6)    648         activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 32, 32, 6)    0           conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_97 (Concatenate)    (None, 32, 32, 18)   0           conv2d_105[0][0]                 \n",
            "                                                                 dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 32, 32, 18)   72          concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 32, 32, 18)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 32, 32, 6)    972         activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 32, 32, 6)    0           conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_98 (Concatenate)    (None, 32, 32, 24)   0           concatenate_97[0][0]             \n",
            "                                                                 dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 32, 32, 24)   96          concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 32, 32, 24)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 32, 32, 6)    1296        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 32, 32, 6)    0           conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_99 (Concatenate)    (None, 32, 32, 30)   0           concatenate_98[0][0]             \n",
            "                                                                 dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 32, 32, 30)   120         concatenate_99[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 32, 32, 30)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 32, 32, 6)    1620        activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, 32, 32, 6)    0           conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_100 (Concatenate)   (None, 32, 32, 36)   0           concatenate_99[0][0]             \n",
            "                                                                 dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 32, 32, 36)   144         concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 32, 32, 36)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 32, 32, 6)    1944        activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 32, 32, 6)    0           conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_101 (Concatenate)   (None, 32, 32, 42)   0           concatenate_100[0][0]            \n",
            "                                                                 dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 32, 32, 42)   168         concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 32, 32, 42)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 32, 32, 6)    2268        activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 32, 32, 6)    0           conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_102 (Concatenate)   (None, 32, 32, 48)   0           concatenate_101[0][0]            \n",
            "                                                                 dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 32, 32, 48)   192         concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 32, 32, 48)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 32, 32, 6)    2592        activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, 32, 32, 6)    0           conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 32, 32, 54)   0           concatenate_102[0][0]            \n",
            "                                                                 dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 32, 32, 54)   216         concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 32, 32, 54)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 32, 32, 6)    2916        activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 32, 32, 6)    0           conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 32, 32, 60)   0           concatenate_103[0][0]            \n",
            "                                                                 dropout_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 32, 32, 60)   240         concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 32, 32, 60)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 32, 32, 6)    3240        activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_111 (Dropout)           (None, 32, 32, 6)    0           conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_105 (Concatenate)   (None, 32, 32, 66)   0           concatenate_104[0][0]            \n",
            "                                                                 dropout_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 32, 32, 66)   264         concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 32, 32, 66)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 6)    3564        activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, 32, 32, 6)    0           conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_106 (Concatenate)   (None, 32, 32, 72)   0           concatenate_105[0][0]            \n",
            "                                                                 dropout_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 32, 32, 72)   288         concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 32, 32, 72)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 32, 32, 6)    3888        activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, 32, 32, 6)    0           conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_107 (Concatenate)   (None, 32, 32, 78)   0           concatenate_106[0][0]            \n",
            "                                                                 dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 32, 32, 78)   312         concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 32, 32, 78)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 32, 32, 6)    4212        activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_114 (Dropout)           (None, 32, 32, 6)    0           conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_108 (Concatenate)   (None, 32, 32, 84)   0           concatenate_107[0][0]            \n",
            "                                                                 dropout_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 32, 32, 84)   336         concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 32, 32, 84)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 32, 32, 6)    504         activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_115 (Dropout)           (None, 32, 32, 6)    0           conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 6)    0           dropout_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 6)    24          average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 6)    0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 6)    324         activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_116 (Dropout)           (None, 16, 16, 6)    0           conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_109 (Concatenate)   (None, 16, 16, 12)   0           average_pooling2d_9[0][0]        \n",
            "                                                                 dropout_116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 12)   48          concatenate_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 12)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 16, 16, 6)    648         activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_117 (Dropout)           (None, 16, 16, 6)    0           conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_110 (Concatenate)   (None, 16, 16, 18)   0           concatenate_109[0][0]            \n",
            "                                                                 dropout_117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 16, 16, 18)   72          concatenate_110[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 16, 16, 18)   0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 6)    972         activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_118 (Dropout)           (None, 16, 16, 6)    0           conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_111 (Concatenate)   (None, 16, 16, 24)   0           concatenate_110[0][0]            \n",
            "                                                                 dropout_118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 24)   96          concatenate_111[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 24)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 6)    1296        activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, 16, 16, 6)    0           conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_112 (Concatenate)   (None, 16, 16, 30)   0           concatenate_111[0][0]            \n",
            "                                                                 dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 30)   120         concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 30)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 16, 16, 6)    1620        activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_120 (Dropout)           (None, 16, 16, 6)    0           conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_113 (Concatenate)   (None, 16, 16, 36)   0           concatenate_112[0][0]            \n",
            "                                                                 dropout_120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 16, 16, 36)   144         concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 16, 16, 36)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 16, 16, 6)    1944        activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_121 (Dropout)           (None, 16, 16, 6)    0           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_114 (Concatenate)   (None, 16, 16, 42)   0           concatenate_113[0][0]            \n",
            "                                                                 dropout_121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 16, 16, 42)   168         concatenate_114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 16, 16, 42)   0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 16, 16, 6)    2268        activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_122 (Dropout)           (None, 16, 16, 6)    0           conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_115 (Concatenate)   (None, 16, 16, 48)   0           concatenate_114[0][0]            \n",
            "                                                                 dropout_122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 16, 16, 48)   192         concatenate_115[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 16, 16, 48)   0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 16, 16, 6)    2592        activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_123 (Dropout)           (None, 16, 16, 6)    0           conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_116 (Concatenate)   (None, 16, 16, 54)   0           concatenate_115[0][0]            \n",
            "                                                                 dropout_123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 16, 16, 54)   216         concatenate_116[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 16, 16, 54)   0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 16, 16, 6)    2916        activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_124 (Dropout)           (None, 16, 16, 6)    0           conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_117 (Concatenate)   (None, 16, 16, 60)   0           concatenate_116[0][0]            \n",
            "                                                                 dropout_124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 16, 16, 60)   240         concatenate_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 16, 16, 60)   0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 16, 16, 6)    3240        activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_125 (Dropout)           (None, 16, 16, 6)    0           conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_118 (Concatenate)   (None, 16, 16, 66)   0           concatenate_117[0][0]            \n",
            "                                                                 dropout_125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 16, 16, 66)   264         concatenate_118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 16, 16, 66)   0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 16, 16, 6)    3564        activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_126 (Dropout)           (None, 16, 16, 6)    0           conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_119 (Concatenate)   (None, 16, 16, 72)   0           concatenate_118[0][0]            \n",
            "                                                                 dropout_126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 16, 16, 72)   288         concatenate_119[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 16, 16, 72)   0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 16, 16, 6)    3888        activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_127 (Dropout)           (None, 16, 16, 6)    0           conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_120 (Concatenate)   (None, 16, 16, 78)   0           concatenate_119[0][0]            \n",
            "                                                                 dropout_127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 16, 16, 78)   312         concatenate_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 16, 16, 78)   0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 16, 16, 6)    468         activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_128 (Dropout)           (None, 16, 16, 6)    0           conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 8, 8, 6)      0           dropout_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 8, 8, 6)      24          average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 8, 8, 6)      0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 8, 8, 6)      324         activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 8, 8, 6)      0           conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 8, 8, 12)     0           average_pooling2d_10[0][0]       \n",
            "                                                                 dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 8, 8, 12)     48          concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 8, 8, 12)     0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 8, 8, 6)      648         activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 8, 8, 6)      0           conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 8, 8, 18)     0           concatenate_121[0][0]            \n",
            "                                                                 dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 8, 8, 18)     72          concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 8, 8, 18)     0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 8, 8, 6)      972         activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_131 (Dropout)           (None, 8, 8, 6)      0           conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_123 (Concatenate)   (None, 8, 8, 24)     0           concatenate_122[0][0]            \n",
            "                                                                 dropout_131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 8, 8, 24)     96          concatenate_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 8, 8, 24)     0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 8, 8, 6)      1296        activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 8, 8, 6)      0           conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_124 (Concatenate)   (None, 8, 8, 30)     0           concatenate_123[0][0]            \n",
            "                                                                 dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 8, 8, 30)     120         concatenate_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 8, 8, 30)     0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 8, 8, 6)      1620        activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 8, 8, 6)      0           conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_125 (Concatenate)   (None, 8, 8, 36)     0           concatenate_124[0][0]            \n",
            "                                                                 dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 8, 8, 36)     144         concatenate_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 8, 8, 36)     0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 8, 8, 6)      1944        activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 8, 8, 6)      0           conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_126 (Concatenate)   (None, 8, 8, 42)     0           concatenate_125[0][0]            \n",
            "                                                                 dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 8, 8, 42)     168         concatenate_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 8, 8, 42)     0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 8, 8, 6)      2268        activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 8, 8, 6)      0           conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_127 (Concatenate)   (None, 8, 8, 48)     0           concatenate_126[0][0]            \n",
            "                                                                 dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 8, 8, 48)     192         concatenate_127[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 8, 8, 48)     0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 8, 8, 6)      2592        activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 8, 8, 6)      0           conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_128 (Concatenate)   (None, 8, 8, 54)     0           concatenate_127[0][0]            \n",
            "                                                                 dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 8, 8, 54)     216         concatenate_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 8, 8, 54)     0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 8, 8, 6)      2916        activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 8, 8, 6)      0           conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_129 (Concatenate)   (None, 8, 8, 60)     0           concatenate_128[0][0]            \n",
            "                                                                 dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 8, 8, 60)     240         concatenate_129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 8, 8, 60)     0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 8, 8, 6)      3240        activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 8, 8, 6)      0           conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_130 (Concatenate)   (None, 8, 8, 66)     0           concatenate_129[0][0]            \n",
            "                                                                 dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 8, 8, 66)     264         concatenate_130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 8, 8, 66)     0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 8, 8, 6)      3564        activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 8, 8, 6)      0           conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_131 (Concatenate)   (None, 8, 8, 72)     0           concatenate_130[0][0]            \n",
            "                                                                 dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 8, 8, 72)     288         concatenate_131[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 8, 8, 72)     0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 8, 8, 6)      3888        activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 8, 8, 6)      0           conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_132 (Concatenate)   (None, 8, 8, 78)     0           concatenate_131[0][0]            \n",
            "                                                                 dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 8, 8, 78)     312         concatenate_132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 8, 8, 78)     0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 8, 8, 6)      468         activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_141 (Dropout)           (None, 8, 8, 6)      0           conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 4, 4, 6)      0           dropout_141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 4, 4, 6)      24          average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 4, 4, 6)      0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 4, 4, 6)      324         activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_142 (Dropout)           (None, 4, 4, 6)      0           conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_133 (Concatenate)   (None, 4, 4, 12)     0           average_pooling2d_11[0][0]       \n",
            "                                                                 dropout_142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 4, 4, 12)     48          concatenate_133[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 4, 4, 12)     0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 4, 4, 6)      648         activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_143 (Dropout)           (None, 4, 4, 6)      0           conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_134 (Concatenate)   (None, 4, 4, 18)     0           concatenate_133[0][0]            \n",
            "                                                                 dropout_143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 4, 4, 18)     72          concatenate_134[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 4, 4, 18)     0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 4, 4, 6)      972         activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_144 (Dropout)           (None, 4, 4, 6)      0           conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_135 (Concatenate)   (None, 4, 4, 24)     0           concatenate_134[0][0]            \n",
            "                                                                 dropout_144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 4, 4, 24)     96          concatenate_135[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 4, 4, 24)     0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 4, 4, 6)      1296        activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_145 (Dropout)           (None, 4, 4, 6)      0           conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_136 (Concatenate)   (None, 4, 4, 30)     0           concatenate_135[0][0]            \n",
            "                                                                 dropout_145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 4, 4, 30)     120         concatenate_136[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 4, 4, 30)     0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 4, 4, 6)      1620        activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_146 (Dropout)           (None, 4, 4, 6)      0           conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_137 (Concatenate)   (None, 4, 4, 36)     0           concatenate_136[0][0]            \n",
            "                                                                 dropout_146[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 4, 4, 36)     144         concatenate_137[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 4, 4, 36)     0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 4, 4, 6)      1944        activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_147 (Dropout)           (None, 4, 4, 6)      0           conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_138 (Concatenate)   (None, 4, 4, 42)     0           concatenate_137[0][0]            \n",
            "                                                                 dropout_147[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 4, 4, 42)     168         concatenate_138[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 4, 4, 42)     0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 4, 4, 6)      2268        activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_148 (Dropout)           (None, 4, 4, 6)      0           conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_139 (Concatenate)   (None, 4, 4, 48)     0           concatenate_138[0][0]            \n",
            "                                                                 dropout_148[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 4, 4, 48)     192         concatenate_139[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 4, 4, 48)     0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 4, 4, 6)      2592        activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_149 (Dropout)           (None, 4, 4, 6)      0           conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_140 (Concatenate)   (None, 4, 4, 54)     0           concatenate_139[0][0]            \n",
            "                                                                 dropout_149[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 4, 4, 54)     216         concatenate_140[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 4, 4, 54)     0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 4, 4, 6)      2916        activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_150 (Dropout)           (None, 4, 4, 6)      0           conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_141 (Concatenate)   (None, 4, 4, 60)     0           concatenate_140[0][0]            \n",
            "                                                                 dropout_150[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 4, 4, 60)     240         concatenate_141[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 4, 4, 60)     0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 4, 4, 6)      3240        activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_151 (Dropout)           (None, 4, 4, 6)      0           conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_142 (Concatenate)   (None, 4, 4, 66)     0           concatenate_141[0][0]            \n",
            "                                                                 dropout_151[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 4, 4, 66)     264         concatenate_142[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 4, 4, 66)     0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 4, 4, 6)      3564        activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_152 (Dropout)           (None, 4, 4, 6)      0           conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_143 (Concatenate)   (None, 4, 4, 72)     0           concatenate_142[0][0]            \n",
            "                                                                 dropout_152[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 4, 4, 72)     288         concatenate_143[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 4, 4, 72)     0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 4, 4, 6)      3888        activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_153 (Dropout)           (None, 4, 4, 6)      0           conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_144 (Concatenate)   (None, 4, 4, 78)     0           concatenate_143[0][0]            \n",
            "                                                                 dropout_153[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 4, 4, 78)     312         concatenate_144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 4, 4, 78)     0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 2, 2, 78)     0           activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 312)          0           average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           3130        flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 118,918\n",
            "Trainable params: 114,394\n",
            "Non-trainable params: 4,524\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n",
        "  \n",
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              #optimizer=Adam(),\n",
        "              optimizer=SGD(lr=0.01, momentum=0.9, decay=0.0001, nesterov=False),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "outputId": "ca7a82a8-6411-4707-dfe9-557987e42443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3394
        }
      },
      "cell_type": "code",
      "source": [
        "#model.fit(x_train, y_train,\n",
        "                    #batch_size=batch_size,\n",
        "                    #epochs=epochs,\n",
        "                    #verbose=1,\n",
        "                    #validation_data=(x_test, y_test))\n",
        "\n",
        " # Fit the model on the batches generated by datagen.flow().\n",
        " #   model.fit_generator(datagen.flow(x_train, y_train,\n",
        " #                                    batch_size=batch_size),\n",
        " #                       epochs=epochs,\n",
        " #                       verbose=1,\n",
        " #                       validation_data=(x_test, y_test),\n",
        " #                       workers=4)\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=100,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test))\n",
        "                    #,callbacks=[LearningRateScheduler(lr_schedule)])\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.8702 - acc: 0.6889 - val_loss: 1.3411 - val_acc: 0.6220\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 119s 304ms/step - loss: 0.8554 - acc: 0.6943 - val_loss: 1.2854 - val_acc: 0.6400\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 118s 301ms/step - loss: 0.8406 - acc: 0.6979 - val_loss: 1.4431 - val_acc: 0.6272\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 120s 308ms/step - loss: 0.8308 - acc: 0.7034 - val_loss: 1.5340 - val_acc: 0.6185\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 121s 310ms/step - loss: 0.8209 - acc: 0.7059 - val_loss: 1.5144 - val_acc: 0.6255\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.8158 - acc: 0.7082 - val_loss: 1.2228 - val_acc: 0.6573\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.8078 - acc: 0.7132 - val_loss: 1.1995 - val_acc: 0.6600\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.7962 - acc: 0.7177 - val_loss: 2.0649 - val_acc: 0.5638\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 119s 306ms/step - loss: 0.7943 - acc: 0.7196 - val_loss: 1.4252 - val_acc: 0.6273\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 118s 301ms/step - loss: 0.7912 - acc: 0.7178 - val_loss: 1.3731 - val_acc: 0.6437\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 121s 311ms/step - loss: 0.7810 - acc: 0.7217 - val_loss: 1.2832 - val_acc: 0.6612\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 119s 305ms/step - loss: 0.7728 - acc: 0.7246 - val_loss: 1.5116 - val_acc: 0.6291\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.7732 - acc: 0.7263 - val_loss: 1.1261 - val_acc: 0.6853\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.7600 - acc: 0.7311 - val_loss: 1.0788 - val_acc: 0.6919\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 119s 305ms/step - loss: 0.7610 - acc: 0.7291 - val_loss: 1.0384 - val_acc: 0.6899\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 121s 311ms/step - loss: 0.7541 - acc: 0.7330 - val_loss: 1.1046 - val_acc: 0.6841\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.7516 - acc: 0.7324 - val_loss: 1.1415 - val_acc: 0.6865\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 118s 304ms/step - loss: 0.7450 - acc: 0.7340 - val_loss: 0.9166 - val_acc: 0.7222\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.7407 - acc: 0.7387 - val_loss: 1.3989 - val_acc: 0.6468\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 120s 307ms/step - loss: 0.7373 - acc: 0.7375 - val_loss: 1.3587 - val_acc: 0.6619\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 119s 306ms/step - loss: 0.7332 - acc: 0.7382 - val_loss: 1.2562 - val_acc: 0.6713\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.7343 - acc: 0.7398 - val_loss: 1.0972 - val_acc: 0.6969\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 118s 304ms/step - loss: 0.7252 - acc: 0.7421 - val_loss: 1.1246 - val_acc: 0.6962\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 120s 307ms/step - loss: 0.7251 - acc: 0.7434 - val_loss: 1.4013 - val_acc: 0.6565\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.7199 - acc: 0.7455 - val_loss: 0.9902 - val_acc: 0.7189\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 121s 311ms/step - loss: 0.7229 - acc: 0.7429 - val_loss: 1.2897 - val_acc: 0.6630\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 119s 306ms/step - loss: 0.7140 - acc: 0.7469 - val_loss: 1.2040 - val_acc: 0.6847\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.7077 - acc: 0.7497 - val_loss: 1.1745 - val_acc: 0.6935\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.7117 - acc: 0.7465 - val_loss: 1.0647 - val_acc: 0.7061\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 120s 307ms/step - loss: 0.7025 - acc: 0.7517 - val_loss: 1.0826 - val_acc: 0.7004\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.7054 - acc: 0.7508 - val_loss: 1.3380 - val_acc: 0.6718\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 122s 312ms/step - loss: 0.7043 - acc: 0.7508 - val_loss: 1.4202 - val_acc: 0.6581\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 120s 306ms/step - loss: 0.6960 - acc: 0.7533 - val_loss: 1.0063 - val_acc: 0.7138\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6976 - acc: 0.7537 - val_loss: 0.9283 - val_acc: 0.7298\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6955 - acc: 0.7552 - val_loss: 1.1787 - val_acc: 0.6924\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 119s 304ms/step - loss: 0.6901 - acc: 0.7570 - val_loss: 0.9436 - val_acc: 0.7299\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6900 - acc: 0.7550 - val_loss: 1.0993 - val_acc: 0.7050\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 121s 310ms/step - loss: 0.6866 - acc: 0.7577 - val_loss: 1.1999 - val_acc: 0.6896\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 121s 309ms/step - loss: 0.6880 - acc: 0.7556 - val_loss: 0.9541 - val_acc: 0.7304\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6833 - acc: 0.7577 - val_loss: 0.9795 - val_acc: 0.7222\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 118s 301ms/step - loss: 0.6802 - acc: 0.7586 - val_loss: 1.0595 - val_acc: 0.7148\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6793 - acc: 0.7591 - val_loss: 0.9116 - val_acc: 0.7370\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 119s 306ms/step - loss: 0.6766 - acc: 0.7611 - val_loss: 0.8645 - val_acc: 0.7483\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 119s 306ms/step - loss: 0.6759 - acc: 0.7622 - val_loss: 0.9525 - val_acc: 0.7310\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 122s 314ms/step - loss: 0.6768 - acc: 0.7625 - val_loss: 1.0389 - val_acc: 0.7195\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6718 - acc: 0.7639 - val_loss: 1.0448 - val_acc: 0.7155\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6689 - acc: 0.7633 - val_loss: 0.8901 - val_acc: 0.7455\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6676 - acc: 0.7644 - val_loss: 0.9539 - val_acc: 0.7312\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 119s 305ms/step - loss: 0.6674 - acc: 0.7633 - val_loss: 1.3962 - val_acc: 0.6716\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 122s 313ms/step - loss: 0.6658 - acc: 0.7666 - val_loss: 1.0034 - val_acc: 0.7317\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6619 - acc: 0.7674 - val_loss: 0.9406 - val_acc: 0.7353\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6623 - acc: 0.7670 - val_loss: 1.1377 - val_acc: 0.7086\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 119s 304ms/step - loss: 0.6669 - acc: 0.7643 - val_loss: 1.1024 - val_acc: 0.7126\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 119s 304ms/step - loss: 0.6601 - acc: 0.7669 - val_loss: 1.0744 - val_acc: 0.7203\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 121s 309ms/step - loss: 0.6576 - acc: 0.7672 - val_loss: 1.0522 - val_acc: 0.7141\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6508 - acc: 0.7693 - val_loss: 0.9227 - val_acc: 0.7374\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6533 - acc: 0.7715 - val_loss: 0.8830 - val_acc: 0.7484\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 119s 305ms/step - loss: 0.6517 - acc: 0.7692 - val_loss: 1.2856 - val_acc: 0.6825\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 119s 304ms/step - loss: 0.6482 - acc: 0.7714 - val_loss: 0.9162 - val_acc: 0.7424\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 122s 313ms/step - loss: 0.6476 - acc: 0.7717 - val_loss: 1.1070 - val_acc: 0.7150\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 120s 307ms/step - loss: 0.6482 - acc: 0.7712 - val_loss: 0.9833 - val_acc: 0.7356\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6508 - acc: 0.7692 - val_loss: 1.0537 - val_acc: 0.7202\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6456 - acc: 0.7727 - val_loss: 1.0189 - val_acc: 0.7267\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6460 - acc: 0.7734 - val_loss: 0.9867 - val_acc: 0.7318\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6445 - acc: 0.7714 - val_loss: 0.8792 - val_acc: 0.7537\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 119s 306ms/step - loss: 0.6426 - acc: 0.7752 - val_loss: 1.0812 - val_acc: 0.7174\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 122s 313ms/step - loss: 0.6440 - acc: 0.7736 - val_loss: 1.0987 - val_acc: 0.7202\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 120s 307ms/step - loss: 0.6413 - acc: 0.7736 - val_loss: 0.8997 - val_acc: 0.7487\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6369 - acc: 0.7749 - val_loss: 1.0186 - val_acc: 0.7273\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6337 - acc: 0.7764 - val_loss: 0.9414 - val_acc: 0.7418\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6337 - acc: 0.7760 - val_loss: 0.9783 - val_acc: 0.7370\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 119s 305ms/step - loss: 0.6390 - acc: 0.7768 - val_loss: 0.8378 - val_acc: 0.7605\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6355 - acc: 0.7759 - val_loss: 1.1750 - val_acc: 0.7044\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 121s 310ms/step - loss: 0.6324 - acc: 0.7769 - val_loss: 1.2398 - val_acc: 0.6957\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 121s 311ms/step - loss: 0.6331 - acc: 0.7775 - val_loss: 1.0676 - val_acc: 0.7144\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6283 - acc: 0.7790 - val_loss: 1.0213 - val_acc: 0.7327\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6286 - acc: 0.7768 - val_loss: 0.9873 - val_acc: 0.7342\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 118s 304ms/step - loss: 0.6296 - acc: 0.7772 - val_loss: 0.9773 - val_acc: 0.7348\n",
            "Epoch 79/100\n",
            "390/390 [==============================] - 120s 307ms/step - loss: 0.6286 - acc: 0.7807 - val_loss: 0.8995 - val_acc: 0.7520\n",
            "Epoch 80/100\n",
            "390/390 [==============================] - 119s 306ms/step - loss: 0.6304 - acc: 0.7797 - val_loss: 0.8987 - val_acc: 0.7511\n",
            "Epoch 81/100\n",
            "390/390 [==============================] - 122s 312ms/step - loss: 0.6272 - acc: 0.7806 - val_loss: 0.9546 - val_acc: 0.7421\n",
            "Epoch 82/100\n",
            "390/390 [==============================] - 119s 306ms/step - loss: 0.6248 - acc: 0.7804 - val_loss: 0.8420 - val_acc: 0.7639\n",
            "Epoch 83/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6221 - acc: 0.7806 - val_loss: 0.8886 - val_acc: 0.7516\n",
            "Epoch 84/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6277 - acc: 0.7786 - val_loss: 0.8983 - val_acc: 0.7549\n",
            "Epoch 85/100\n",
            "390/390 [==============================] - 119s 305ms/step - loss: 0.6237 - acc: 0.7808 - val_loss: 0.8809 - val_acc: 0.7574\n",
            "Epoch 86/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6230 - acc: 0.7802 - val_loss: 0.8895 - val_acc: 0.7543\n",
            "Epoch 87/100\n",
            "390/390 [==============================] - 120s 309ms/step - loss: 0.6211 - acc: 0.7831 - val_loss: 0.8773 - val_acc: 0.7573\n",
            "Epoch 88/100\n",
            "390/390 [==============================] - 121s 309ms/step - loss: 0.6245 - acc: 0.7808 - val_loss: 1.0721 - val_acc: 0.7243\n",
            "Epoch 89/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6256 - acc: 0.7802 - val_loss: 0.9531 - val_acc: 0.7407\n",
            "Epoch 90/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6195 - acc: 0.7818 - val_loss: 0.9061 - val_acc: 0.7426\n",
            "Epoch 91/100\n",
            "390/390 [==============================] - 119s 304ms/step - loss: 0.6202 - acc: 0.7807 - val_loss: 0.9234 - val_acc: 0.7435\n",
            "Epoch 92/100\n",
            "390/390 [==============================] - 120s 307ms/step - loss: 0.6176 - acc: 0.7831 - val_loss: 0.8790 - val_acc: 0.7553\n",
            "Epoch 93/100\n",
            "390/390 [==============================] - 121s 311ms/step - loss: 0.6169 - acc: 0.7814 - val_loss: 1.0954 - val_acc: 0.7202\n",
            "Epoch 94/100\n",
            "390/390 [==============================] - 118s 301ms/step - loss: 0.6224 - acc: 0.7808 - val_loss: 0.9465 - val_acc: 0.7469\n",
            "Epoch 95/100\n",
            "390/390 [==============================] - 118s 302ms/step - loss: 0.6117 - acc: 0.7858 - val_loss: 0.8089 - val_acc: 0.7660\n",
            "Epoch 96/100\n",
            "390/390 [==============================] - 118s 303ms/step - loss: 0.6136 - acc: 0.7853 - val_loss: 0.9181 - val_acc: 0.7491\n",
            "Epoch 97/100\n",
            "390/390 [==============================] - 119s 306ms/step - loss: 0.6121 - acc: 0.7849 - val_loss: 0.9671 - val_acc: 0.7461\n",
            "Epoch 98/100\n",
            "390/390 [==============================] - 121s 311ms/step - loss: 0.6107 - acc: 0.7863 - val_loss: 0.9139 - val_acc: 0.7525\n",
            "Epoch 99/100\n",
            "390/390 [==============================] - 119s 305ms/step - loss: 0.6126 - acc: 0.7839 - val_loss: 1.0580 - val_acc: 0.7270\n",
            "Epoch 100/100\n",
            "390/390 [==============================] - 118s 304ms/step - loss: 0.6117 - acc: 0.7855 - val_loss: 1.0134 - val_acc: 0.7321\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ba9217470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "outputId": "12ce8dbc-7a84-4179-f7b9-57b8c68c3a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 12s 1ms/step\n",
            "Test loss: 1.013374768257141\n",
            "Test accuracy: 0.7321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "outputId": "eb4f5465-a02a-432b-87dd-4572c00ff1be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "outputId": "f6d36898-e462-4f76-feeb-910d1192dc82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-a1e1084f0aae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DNST_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: NetworkError when attempting to fetch resource."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}